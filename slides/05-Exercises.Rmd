---
title: "Exercises for Bayesian Hierarchical models"
author: Bruno Nicenboim and Shravan Vasishth
output: pdf_document
bibliography: ["BayesCogSci.bib", "packages.bib"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## 1. By-participants and by-items N400 model

Everything I said about by-participants group level (or random effects) is also relevant for by-items. Fit a by-participants and by-items maximal model.


## 2. Hierarchical model with a lognormal likelihood

 We begin with a classic question from the psycholinguistics literature: Are subject relatives easier to process than object relatives? The data come from Experiment 1 in a paper by @grodner.

 *Scientific question*: Is there a subject relative advantage in reading?

 In two important papers, @gibson00 and @grodner suggest that object relative clause (ORC) sentences are more difficult to process than subject relative clause (SRC) sentences because the distance between the relative clause verb (e.g., "*sent*" in the example below) and the head noun phrase of the relative clause (e.g.,  "*reporter*" below) is longer in ORC vs SRC. Examples are shown below.

 (1a) The *reporter* who the photographer *sent* to the editor was hoping for a good story. (ORC)

 (1b) The *reporter* who *sent* the photographer to the editor was hoping for a good story. (SRC)

 The underlying explanation has to do with memory processes: Shorter linguistic dependencies are easier to process due to either reduced interference or decay, or both. For implemented computational models that spell this point out, see @lewisvasishth:cogsci05 and @EngelmannJaegerVasishthSubmitted2018.

 In the Grodner and Gibson data, the dependent measure is reading time at the relative clause verb, (e.g., "*sent*") of different sentences with either ORC or SRC. The dependent variable is in milliseconds and was measured in a self-paced reading task. [Self-paced reading is a task where participants read a sentence or a short text word-by-word or phrase-by-phrase, pressing a button to get the next word or phrase displayed while the previous one disappears; @aaronsonPerformanceTheoriesSentence1976; @mitchellEffectsContextContent1978]. For this experiment, we are expecting longer reading times at the relative close verbs of ORC sentences in comparison to the relative close verb of SRC sentences.



```{r open_grodneretal, message = FALSE}
library(dplyr)
library(readr)
gg05_data <- read_csv("data/GrodnerGibson2005E1.csv") %>%
    filter(item != 0) %>%
    mutate(word_positionnew = if_else(item != 15 & 
                                             word_position > 10, 
                                             word_position-1, 
                                             word_position))
#there is a mistake in the coding of word position,
#all items but 15 have regions 10 and higher coded
#as words 11 and higher

## get data from relative clause verb:
rc_data <- gg05_data %>%
  filter((condition == "objgap" & word_position == 6 ) |
            ( condition == "subjgap" & word_position == 4 ))
```
You should use a sum coding for the predictors. Here, object gaps are coded $+1$, subject gaps $-1$.

```{r}
rc_data <- rc_data %>%
  mutate(c_cond = if_else(condition == "objgap",  1, -1))
```

You should be able to now fit a maximal model (correlated varying intercept and slopes for subjects and items) assuming a lognormal likelihood, and examine the effect of relative clause attachment site (the predictor `c_cond`) on reading times `rawRT`. For the population-level parameters, try to use the same priors that we elicited in our log-normal regression.  Is the prior for $\beta$ ($\beta \sim Normal(0, .1)$) appropriate? Do a sensitivity analysis. What is the estimate of the effect ($\beta$) under different priors? What is the difference in milliseconds between conditions under different priors?


## References
